{"version":3,"file":"487.index.js","mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":[".././node_modules/@apollo/server/node_modules/lru-cache/index.mjs"],"sourcesContent":["const perf =\n  typeof performance === 'object' &&\n  performance &&\n  typeof performance.now === 'function'\n    ? performance\n    : Date\n\nconst hasAbortController = typeof AbortController === 'function'\n\n// minimal backwards-compatibility polyfill\n// this doesn't have nearly all the checks and whatnot that\n// actual AbortController/Signal has, but it's enough for\n// our purposes, and if used properly, behaves the same.\nconst AC = hasAbortController\n  ? AbortController\n  : class AbortController {\n      constructor() {\n        this.signal = new AS()\n      }\n      abort(reason = new Error('This operation was aborted')) {\n        this.signal.reason = this.signal.reason || reason\n        this.signal.aborted = true\n        this.signal.dispatchEvent({\n          type: 'abort',\n          target: this.signal,\n        })\n      }\n    }\n\nconst hasAbortSignal = typeof AbortSignal === 'function'\n// Some polyfills put this on the AC class, not global\nconst hasACAbortSignal = typeof AC.AbortSignal === 'function'\nconst AS = hasAbortSignal\n  ? AbortSignal\n  : hasACAbortSignal\n  ? AC.AbortController\n  : class AbortSignal {\n      constructor() {\n        this.reason = undefined\n        this.aborted = false\n        this._listeners = []\n      }\n      dispatchEvent(e) {\n        if (e.type === 'abort') {\n          this.aborted = true\n          this.onabort(e)\n          this._listeners.forEach(f => f(e), this)\n        }\n      }\n      onabort() {}\n      addEventListener(ev, fn) {\n        if (ev === 'abort') {\n          this._listeners.push(fn)\n        }\n      }\n      removeEventListener(ev, fn) {\n        if (ev === 'abort') {\n          this._listeners = this._listeners.filter(f => f !== fn)\n        }\n      }\n    }\n\nconst warned = new Set()\nconst deprecatedOption = (opt, instead) => {\n  const code = `LRU_CACHE_OPTION_${opt}`\n  if (shouldWarn(code)) {\n    warn(code, `${opt} option`, `options.${instead}`, LRUCache)\n  }\n}\nconst deprecatedMethod = (method, instead) => {\n  const code = `LRU_CACHE_METHOD_${method}`\n  if (shouldWarn(code)) {\n    const { prototype } = LRUCache\n    const { get } = Object.getOwnPropertyDescriptor(prototype, method)\n    warn(code, `${method} method`, `cache.${instead}()`, get)\n  }\n}\nconst deprecatedProperty = (field, instead) => {\n  const code = `LRU_CACHE_PROPERTY_${field}`\n  if (shouldWarn(code)) {\n    const { prototype } = LRUCache\n    const { get } = Object.getOwnPropertyDescriptor(prototype, field)\n    warn(code, `${field} property`, `cache.${instead}`, get)\n  }\n}\n\nconst emitWarning = (...a) => {\n  typeof process === 'object' &&\n  process &&\n  typeof process.emitWarning === 'function'\n    ? process.emitWarning(...a)\n    : console.error(...a)\n}\n\nconst shouldWarn = code => !warned.has(code)\n\nconst warn = (code, what, instead, fn) => {\n  warned.add(code)\n  const msg = `The ${what} is deprecated. Please use ${instead} instead.`\n  emitWarning(msg, 'DeprecationWarning', code, fn)\n}\n\nconst isPosInt = n => n && n === Math.floor(n) && n > 0 && isFinite(n)\n\n/* istanbul ignore next - This is a little bit ridiculous, tbh.\n * The maximum array length is 2^32-1 or thereabouts on most JS impls.\n * And well before that point, you're caching the entire world, I mean,\n * that's ~32GB of just integers for the next/prev links, plus whatever\n * else to hold that many keys and values.  Just filling the memory with\n * zeroes at init time is brutal when you get that big.\n * But why not be complete?\n * Maybe in the future, these limits will have expanded. */\nconst getUintArray = max =>\n  !isPosInt(max)\n    ? null\n    : max <= Math.pow(2, 8)\n    ? Uint8Array\n    : max <= Math.pow(2, 16)\n    ? Uint16Array\n    : max <= Math.pow(2, 32)\n    ? Uint32Array\n    : max <= Number.MAX_SAFE_INTEGER\n    ? ZeroArray\n    : null\n\nclass ZeroArray extends Array {\n  constructor(size) {\n    super(size)\n    this.fill(0)\n  }\n}\n\nclass Stack {\n  constructor(max) {\n    if (max === 0) {\n      return []\n    }\n    const UintArray = getUintArray(max)\n    this.heap = new UintArray(max)\n    this.length = 0\n  }\n  push(n) {\n    this.heap[this.length++] = n\n  }\n  pop() {\n    return this.heap[--this.length]\n  }\n}\n\nclass LRUCache {\n  constructor(options = {}) {\n    const {\n      max = 0,\n      ttl,\n      ttlResolution = 1,\n      ttlAutopurge,\n      updateAgeOnGet,\n      updateAgeOnHas,\n      allowStale,\n      dispose,\n      disposeAfter,\n      noDisposeOnSet,\n      noUpdateTTL,\n      maxSize = 0,\n      maxEntrySize = 0,\n      sizeCalculation,\n      fetchMethod,\n      fetchContext,\n      noDeleteOnFetchRejection,\n      noDeleteOnStaleGet,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n    } = options\n\n    // deprecated options, don't trigger a warning for getting them if\n    // the thing being passed in is another LRUCache we're copying.\n    const { length, maxAge, stale } =\n      options instanceof LRUCache ? {} : options\n\n    if (max !== 0 && !isPosInt(max)) {\n      throw new TypeError('max option must be a nonnegative integer')\n    }\n\n    const UintArray = max ? getUintArray(max) : Array\n    if (!UintArray) {\n      throw new Error('invalid max value: ' + max)\n    }\n\n    this.max = max\n    this.maxSize = maxSize\n    this.maxEntrySize = maxEntrySize || this.maxSize\n    this.sizeCalculation = sizeCalculation || length\n    if (this.sizeCalculation) {\n      if (!this.maxSize && !this.maxEntrySize) {\n        throw new TypeError(\n          'cannot set sizeCalculation without setting maxSize or maxEntrySize'\n        )\n      }\n      if (typeof this.sizeCalculation !== 'function') {\n        throw new TypeError('sizeCalculation set to non-function')\n      }\n    }\n\n    this.fetchMethod = fetchMethod || null\n    if (this.fetchMethod && typeof this.fetchMethod !== 'function') {\n      throw new TypeError(\n        'fetchMethod must be a function if specified'\n      )\n    }\n\n    this.fetchContext = fetchContext\n    if (!this.fetchMethod && fetchContext !== undefined) {\n      throw new TypeError(\n        'cannot set fetchContext without fetchMethod'\n      )\n    }\n\n    this.keyMap = new Map()\n    this.keyList = new Array(max).fill(null)\n    this.valList = new Array(max).fill(null)\n    this.next = new UintArray(max)\n    this.prev = new UintArray(max)\n    this.head = 0\n    this.tail = 0\n    this.free = new Stack(max)\n    this.initialFill = 1\n    this.size = 0\n\n    if (typeof dispose === 'function') {\n      this.dispose = dispose\n    }\n    if (typeof disposeAfter === 'function') {\n      this.disposeAfter = disposeAfter\n      this.disposed = []\n    } else {\n      this.disposeAfter = null\n      this.disposed = null\n    }\n    this.noDisposeOnSet = !!noDisposeOnSet\n    this.noUpdateTTL = !!noUpdateTTL\n    this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection\n    this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection\n    this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort\n    this.ignoreFetchAbort = !!ignoreFetchAbort\n\n    // NB: maxEntrySize is set to maxSize if it's set\n    if (this.maxEntrySize !== 0) {\n      if (this.maxSize !== 0) {\n        if (!isPosInt(this.maxSize)) {\n          throw new TypeError(\n            'maxSize must be a positive integer if specified'\n          )\n        }\n      }\n      if (!isPosInt(this.maxEntrySize)) {\n        throw new TypeError(\n          'maxEntrySize must be a positive integer if specified'\n        )\n      }\n      this.initializeSizeTracking()\n    }\n\n    this.allowStale = !!allowStale || !!stale\n    this.noDeleteOnStaleGet = !!noDeleteOnStaleGet\n    this.updateAgeOnGet = !!updateAgeOnGet\n    this.updateAgeOnHas = !!updateAgeOnHas\n    this.ttlResolution =\n      isPosInt(ttlResolution) || ttlResolution === 0\n        ? ttlResolution\n        : 1\n    this.ttlAutopurge = !!ttlAutopurge\n    this.ttl = ttl || maxAge || 0\n    if (this.ttl) {\n      if (!isPosInt(this.ttl)) {\n        throw new TypeError(\n          'ttl must be a positive integer if specified'\n        )\n      }\n      this.initializeTTLTracking()\n    }\n\n    // do not allow completely unbounded caches\n    if (this.max === 0 && this.ttl === 0 && this.maxSize === 0) {\n      throw new TypeError(\n        'At least one of max, maxSize, or ttl is required'\n      )\n    }\n    if (!this.ttlAutopurge && !this.max && !this.maxSize) {\n      const code = 'LRU_CACHE_UNBOUNDED'\n      if (shouldWarn(code)) {\n        warned.add(code)\n        const msg =\n          'TTL caching without ttlAutopurge, max, or maxSize can ' +\n          'result in unbounded memory consumption.'\n        emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)\n      }\n    }\n\n    if (stale) {\n      deprecatedOption('stale', 'allowStale')\n    }\n    if (maxAge) {\n      deprecatedOption('maxAge', 'ttl')\n    }\n    if (length) {\n      deprecatedOption('length', 'sizeCalculation')\n    }\n  }\n\n  getRemainingTTL(key) {\n    return this.has(key, { updateAgeOnHas: false }) ? Infinity : 0\n  }\n\n  initializeTTLTracking() {\n    this.ttls = new ZeroArray(this.max)\n    this.starts = new ZeroArray(this.max)\n\n    this.setItemTTL = (index, ttl, start = perf.now()) => {\n      this.starts[index] = ttl !== 0 ? start : 0\n      this.ttls[index] = ttl\n      if (ttl !== 0 && this.ttlAutopurge) {\n        const t = setTimeout(() => {\n          if (this.isStale(index)) {\n            this.delete(this.keyList[index])\n          }\n        }, ttl + 1)\n        /* istanbul ignore else - unref() not supported on all platforms */\n        if (t.unref) {\n          t.unref()\n        }\n      }\n    }\n\n    this.updateItemAge = index => {\n      this.starts[index] = this.ttls[index] !== 0 ? perf.now() : 0\n    }\n\n    this.statusTTL = (status, index) => {\n      if (status) {\n        status.ttl = this.ttls[index]\n        status.start = this.starts[index]\n        status.now = cachedNow || getNow()\n        status.remainingTTL = status.now + status.ttl - status.start\n      }\n    }\n\n    // debounce calls to perf.now() to 1s so we're not hitting\n    // that costly call repeatedly.\n    let cachedNow = 0\n    const getNow = () => {\n      const n = perf.now()\n      if (this.ttlResolution > 0) {\n        cachedNow = n\n        const t = setTimeout(\n          () => (cachedNow = 0),\n          this.ttlResolution\n        )\n        /* istanbul ignore else - not available on all platforms */\n        if (t.unref) {\n          t.unref()\n        }\n      }\n      return n\n    }\n\n    this.getRemainingTTL = key => {\n      const index = this.keyMap.get(key)\n      if (index === undefined) {\n        return 0\n      }\n      return this.ttls[index] === 0 || this.starts[index] === 0\n        ? Infinity\n        : this.starts[index] +\n            this.ttls[index] -\n            (cachedNow || getNow())\n    }\n\n    this.isStale = index => {\n      return (\n        this.ttls[index] !== 0 &&\n        this.starts[index] !== 0 &&\n        (cachedNow || getNow()) - this.starts[index] >\n          this.ttls[index]\n      )\n    }\n  }\n  updateItemAge(_index) {}\n  statusTTL(_status, _index) {}\n  setItemTTL(_index, _ttl, _start) {}\n  isStale(_index) {\n    return false\n  }\n\n  initializeSizeTracking() {\n    this.calculatedSize = 0\n    this.sizes = new ZeroArray(this.max)\n    this.removeItemSize = index => {\n      this.calculatedSize -= this.sizes[index]\n      this.sizes[index] = 0\n    }\n    this.requireSize = (k, v, size, sizeCalculation) => {\n      // provisionally accept background fetches.\n      // actual value size will be checked when they return.\n      if (this.isBackgroundFetch(v)) {\n        return 0\n      }\n      if (!isPosInt(size)) {\n        if (sizeCalculation) {\n          if (typeof sizeCalculation !== 'function') {\n            throw new TypeError('sizeCalculation must be a function')\n          }\n          size = sizeCalculation(v, k)\n          if (!isPosInt(size)) {\n            throw new TypeError(\n              'sizeCalculation return invalid (expect positive integer)'\n            )\n          }\n        } else {\n          throw new TypeError(\n            'invalid size value (must be positive integer). ' +\n              'When maxSize or maxEntrySize is used, sizeCalculation or size ' +\n              'must be set.'\n          )\n        }\n      }\n      return size\n    }\n    this.addItemSize = (index, size, status) => {\n      this.sizes[index] = size\n      if (this.maxSize) {\n        const maxSize = this.maxSize - this.sizes[index]\n        while (this.calculatedSize > maxSize) {\n          this.evict(true)\n        }\n      }\n      this.calculatedSize += this.sizes[index]\n      if (status) {\n        status.entrySize = size\n        status.totalCalculatedSize = this.calculatedSize\n      }\n    }\n  }\n  removeItemSize(_index) {}\n  addItemSize(_index, _size) {}\n  requireSize(_k, _v, size, sizeCalculation) {\n    if (size || sizeCalculation) {\n      throw new TypeError(\n        'cannot set size without setting maxSize or maxEntrySize on cache'\n      )\n    }\n  }\n\n  *indexes({ allowStale = this.allowStale } = {}) {\n    if (this.size) {\n      for (let i = this.tail; true; ) {\n        if (!this.isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.isStale(i)) {\n          yield i\n        }\n        if (i === this.head) {\n          break\n        } else {\n          i = this.prev[i]\n        }\n      }\n    }\n  }\n\n  *rindexes({ allowStale = this.allowStale } = {}) {\n    if (this.size) {\n      for (let i = this.head; true; ) {\n        if (!this.isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.isStale(i)) {\n          yield i\n        }\n        if (i === this.tail) {\n          break\n        } else {\n          i = this.next[i]\n        }\n      }\n    }\n  }\n\n  isValidIndex(index) {\n    return (\n      index !== undefined &&\n      this.keyMap.get(this.keyList[index]) === index\n    )\n  }\n\n  *entries() {\n    for (const i of this.indexes()) {\n      if (\n        this.valList[i] !== undefined &&\n        this.keyList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield [this.keyList[i], this.valList[i]]\n      }\n    }\n  }\n  *rentries() {\n    for (const i of this.rindexes()) {\n      if (\n        this.valList[i] !== undefined &&\n        this.keyList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield [this.keyList[i], this.valList[i]]\n      }\n    }\n  }\n\n  *keys() {\n    for (const i of this.indexes()) {\n      if (\n        this.keyList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield this.keyList[i]\n      }\n    }\n  }\n  *rkeys() {\n    for (const i of this.rindexes()) {\n      if (\n        this.keyList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield this.keyList[i]\n      }\n    }\n  }\n\n  *values() {\n    for (const i of this.indexes()) {\n      if (\n        this.valList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield this.valList[i]\n      }\n    }\n  }\n  *rvalues() {\n    for (const i of this.rindexes()) {\n      if (\n        this.valList[i] !== undefined &&\n        !this.isBackgroundFetch(this.valList[i])\n      ) {\n        yield this.valList[i]\n      }\n    }\n  }\n\n  [Symbol.iterator]() {\n    return this.entries()\n  }\n\n  find(fn, getOptions) {\n    for (const i of this.indexes()) {\n      const v = this.valList[i]\n      const value = this.isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      if (fn(value, this.keyList[i], this)) {\n        return this.get(this.keyList[i], getOptions)\n      }\n    }\n  }\n\n  forEach(fn, thisp = this) {\n    for (const i of this.indexes()) {\n      const v = this.valList[i]\n      const value = this.isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.keyList[i], this)\n    }\n  }\n\n  rforEach(fn, thisp = this) {\n    for (const i of this.rindexes()) {\n      const v = this.valList[i]\n      const value = this.isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.keyList[i], this)\n    }\n  }\n\n  get prune() {\n    deprecatedMethod('prune', 'purgeStale')\n    return this.purgeStale\n  }\n\n  purgeStale() {\n    let deleted = false\n    for (const i of this.rindexes({ allowStale: true })) {\n      if (this.isStale(i)) {\n        this.delete(this.keyList[i])\n        deleted = true\n      }\n    }\n    return deleted\n  }\n\n  dump() {\n    const arr = []\n    for (const i of this.indexes({ allowStale: true })) {\n      const key = this.keyList[i]\n      const v = this.valList[i]\n      const value = this.isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      const entry = { value }\n      if (this.ttls) {\n        entry.ttl = this.ttls[i]\n        // always dump the start relative to a portable timestamp\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = perf.now() - this.starts[i]\n        entry.start = Math.floor(Date.now() - age)\n      }\n      if (this.sizes) {\n        entry.size = this.sizes[i]\n      }\n      arr.unshift([key, entry])\n    }\n    return arr\n  }\n\n  load(arr) {\n    this.clear()\n    for (const [key, entry] of arr) {\n      if (entry.start) {\n        // entry.start is a portable timestamp, but we may be using\n        // node's performance.now(), so calculate the offset.\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = Date.now() - entry.start\n        entry.start = perf.now() - age\n      }\n      this.set(key, entry.value, entry)\n    }\n  }\n\n  dispose(_v, _k, _reason) {}\n\n  set(\n    k,\n    v,\n    {\n      ttl = this.ttl,\n      start,\n      noDisposeOnSet = this.noDisposeOnSet,\n      size = 0,\n      sizeCalculation = this.sizeCalculation,\n      noUpdateTTL = this.noUpdateTTL,\n      status,\n    } = {}\n  ) {\n    size = this.requireSize(k, v, size, sizeCalculation)\n    // if the item doesn't fit, don't do anything\n    // NB: maxEntrySize set to maxSize by default\n    if (this.maxEntrySize && size > this.maxEntrySize) {\n      if (status) {\n        status.set = 'miss'\n        status.maxEntrySizeExceeded = true\n      }\n      // have to delete, in case a background fetch is there already.\n      // in non-async cases, this is a no-op\n      this.delete(k)\n      return this\n    }\n    let index = this.size === 0 ? undefined : this.keyMap.get(k)\n    if (index === undefined) {\n      // addition\n      index = this.newIndex()\n      this.keyList[index] = k\n      this.valList[index] = v\n      this.keyMap.set(k, index)\n      this.next[this.tail] = index\n      this.prev[index] = this.tail\n      this.tail = index\n      this.size++\n      this.addItemSize(index, size, status)\n      if (status) {\n        status.set = 'add'\n      }\n      noUpdateTTL = false\n    } else {\n      // update\n      this.moveToTail(index)\n      const oldVal = this.valList[index]\n      if (v !== oldVal) {\n        if (this.isBackgroundFetch(oldVal)) {\n          oldVal.__abortController.abort(new Error('replaced'))\n        } else {\n          if (!noDisposeOnSet) {\n            this.dispose(oldVal, k, 'set')\n            if (this.disposeAfter) {\n              this.disposed.push([oldVal, k, 'set'])\n            }\n          }\n        }\n        this.removeItemSize(index)\n        this.valList[index] = v\n        this.addItemSize(index, size, status)\n        if (status) {\n          status.set = 'replace'\n          const oldValue =\n            oldVal && this.isBackgroundFetch(oldVal)\n              ? oldVal.__staleWhileFetching\n              : oldVal\n          if (oldValue !== undefined) status.oldValue = oldValue\n        }\n      } else if (status) {\n        status.set = 'update'\n      }\n    }\n    if (ttl !== 0 && this.ttl === 0 && !this.ttls) {\n      this.initializeTTLTracking()\n    }\n    if (!noUpdateTTL) {\n      this.setItemTTL(index, ttl, start)\n    }\n    this.statusTTL(status, index)\n    if (this.disposeAfter) {\n      while (this.disposed.length) {\n        this.disposeAfter(...this.disposed.shift())\n      }\n    }\n    return this\n  }\n\n  newIndex() {\n    if (this.size === 0) {\n      return this.tail\n    }\n    if (this.size === this.max && this.max !== 0) {\n      return this.evict(false)\n    }\n    if (this.free.length !== 0) {\n      return this.free.pop()\n    }\n    // initial fill, just keep writing down the list\n    return this.initialFill++\n  }\n\n  pop() {\n    if (this.size) {\n      const val = this.valList[this.head]\n      this.evict(true)\n      return val\n    }\n  }\n\n  evict(free) {\n    const head = this.head\n    const k = this.keyList[head]\n    const v = this.valList[head]\n    if (this.isBackgroundFetch(v)) {\n      v.__abortController.abort(new Error('evicted'))\n    } else {\n      this.dispose(v, k, 'evict')\n      if (this.disposeAfter) {\n        this.disposed.push([v, k, 'evict'])\n      }\n    }\n    this.removeItemSize(head)\n    // if we aren't about to use the index, then null these out\n    if (free) {\n      this.keyList[head] = null\n      this.valList[head] = null\n      this.free.push(head)\n    }\n    this.head = this.next[head]\n    this.keyMap.delete(k)\n    this.size--\n    return head\n  }\n\n  has(k, { updateAgeOnHas = this.updateAgeOnHas, status } = {}) {\n    const index = this.keyMap.get(k)\n    if (index !== undefined) {\n      if (!this.isStale(index)) {\n        if (updateAgeOnHas) {\n          this.updateItemAge(index)\n        }\n        if (status) status.has = 'hit'\n        this.statusTTL(status, index)\n        return true\n      } else if (status) {\n        status.has = 'stale'\n        this.statusTTL(status, index)\n      }\n    } else if (status) {\n      status.has = 'miss'\n    }\n    return false\n  }\n\n  // like get(), but without any LRU updating or TTL expiration\n  peek(k, { allowStale = this.allowStale } = {}) {\n    const index = this.keyMap.get(k)\n    if (index !== undefined && (allowStale || !this.isStale(index))) {\n      const v = this.valList[index]\n      // either stale and allowed, or forcing a refresh of non-stale value\n      return this.isBackgroundFetch(v) ? v.__staleWhileFetching : v\n    }\n  }\n\n  backgroundFetch(k, index, options, context) {\n    const v = index === undefined ? undefined : this.valList[index]\n    if (this.isBackgroundFetch(v)) {\n      return v\n    }\n    const ac = new AC()\n    if (options.signal) {\n      options.signal.addEventListener('abort', () =>\n        ac.abort(options.signal.reason)\n      )\n    }\n    const fetchOpts = {\n      signal: ac.signal,\n      options,\n      context,\n    }\n    const cb = (v, updateCache = false) => {\n      const { aborted } = ac.signal\n      const ignoreAbort = options.ignoreFetchAbort && v !== undefined\n      if (options.status) {\n        if (aborted && !updateCache) {\n          options.status.fetchAborted = true\n          options.status.fetchError = ac.signal.reason\n          if (ignoreAbort) options.status.fetchAbortIgnored = true\n        } else {\n          options.status.fetchResolved = true\n        }\n      }\n      if (aborted && !ignoreAbort && !updateCache) {\n        return fetchFail(ac.signal.reason)\n      }\n      // either we didn't abort, and are still here, or we did, and ignored\n      if (this.valList[index] === p) {\n        if (v === undefined) {\n          if (p.__staleWhileFetching) {\n            this.valList[index] = p.__staleWhileFetching\n          } else {\n            this.delete(k)\n          }\n        } else {\n          if (options.status) options.status.fetchUpdated = true\n          this.set(k, v, fetchOpts.options)\n        }\n      }\n      return v\n    }\n    const eb = er => {\n      if (options.status) {\n        options.status.fetchRejected = true\n        options.status.fetchError = er\n      }\n      return fetchFail(er)\n    }\n    const fetchFail = er => {\n      const { aborted } = ac.signal\n      const allowStaleAborted =\n        aborted && options.allowStaleOnFetchAbort\n      const allowStale =\n        allowStaleAborted || options.allowStaleOnFetchRejection\n      const noDelete = allowStale || options.noDeleteOnFetchRejection\n      if (this.valList[index] === p) {\n        // if we allow stale on fetch rejections, then we need to ensure that\n        // the stale value is not removed from the cache when the fetch fails.\n        const del = !noDelete || p.__staleWhileFetching === undefined\n        if (del) {\n          this.delete(k)\n        } else if (!allowStaleAborted) {\n          // still replace the *promise* with the stale value,\n          // since we are done with the promise at this point.\n          // leave it untouched if we're still waiting for an\n          // aborted background fetch that hasn't yet returned.\n          this.valList[index] = p.__staleWhileFetching\n        }\n      }\n      if (allowStale) {\n        if (options.status && p.__staleWhileFetching !== undefined) {\n          options.status.returnedStale = true\n        }\n        return p.__staleWhileFetching\n      } else if (p.__returned === p) {\n        throw er\n      }\n    }\n    const pcall = (res, rej) => {\n      this.fetchMethod(k, v, fetchOpts).then(v => res(v), rej)\n      // ignored, we go until we finish, regardless.\n      // defer check until we are actually aborting,\n      // so fetchMethod can override.\n      ac.signal.addEventListener('abort', () => {\n        if (\n          !options.ignoreFetchAbort ||\n          options.allowStaleOnFetchAbort\n        ) {\n          res()\n          // when it eventually resolves, update the cache.\n          if (options.allowStaleOnFetchAbort) {\n            res = v => cb(v, true)\n          }\n        }\n      })\n    }\n    if (options.status) options.status.fetchDispatched = true\n    const p = new Promise(pcall).then(cb, eb)\n    p.__abortController = ac\n    p.__staleWhileFetching = v\n    p.__returned = null\n    if (index === undefined) {\n      // internal, don't expose status.\n      this.set(k, p, { ...fetchOpts.options, status: undefined })\n      index = this.keyMap.get(k)\n    } else {\n      this.valList[index] = p\n    }\n    return p\n  }\n\n  isBackgroundFetch(p) {\n    return (\n      p &&\n      typeof p === 'object' &&\n      typeof p.then === 'function' &&\n      Object.prototype.hasOwnProperty.call(\n        p,\n        '__staleWhileFetching'\n      ) &&\n      Object.prototype.hasOwnProperty.call(p, '__returned') &&\n      (p.__returned === p || p.__returned === null)\n    )\n  }\n\n  // this takes the union of get() and set() opts, because it does both\n  async fetch(\n    k,\n    {\n      // get options\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      // set options\n      ttl = this.ttl,\n      noDisposeOnSet = this.noDisposeOnSet,\n      size = 0,\n      sizeCalculation = this.sizeCalculation,\n      noUpdateTTL = this.noUpdateTTL,\n      // fetch exclusive options\n      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,\n      ignoreFetchAbort = this.ignoreFetchAbort,\n      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,\n      fetchContext = this.fetchContext,\n      forceRefresh = false,\n      status,\n      signal,\n    } = {}\n  ) {\n    if (!this.fetchMethod) {\n      if (status) status.fetch = 'get'\n      return this.get(k, {\n        allowStale,\n        updateAgeOnGet,\n        noDeleteOnStaleGet,\n        status,\n      })\n    }\n\n    const options = {\n      allowStale,\n      updateAgeOnGet,\n      noDeleteOnStaleGet,\n      ttl,\n      noDisposeOnSet,\n      size,\n      sizeCalculation,\n      noUpdateTTL,\n      noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n      status,\n      signal,\n    }\n\n    let index = this.keyMap.get(k)\n    if (index === undefined) {\n      if (status) status.fetch = 'miss'\n      const p = this.backgroundFetch(k, index, options, fetchContext)\n      return (p.__returned = p)\n    } else {\n      // in cache, maybe already fetching\n      const v = this.valList[index]\n      if (this.isBackgroundFetch(v)) {\n        const stale =\n          allowStale && v.__staleWhileFetching !== undefined\n        if (status) {\n          status.fetch = 'inflight'\n          if (stale) status.returnedStale = true\n        }\n        return stale ? v.__staleWhileFetching : (v.__returned = v)\n      }\n\n      // if we force a refresh, that means do NOT serve the cached value,\n      // unless we are already in the process of refreshing the cache.\n      const isStale = this.isStale(index)\n      if (!forceRefresh && !isStale) {\n        if (status) status.fetch = 'hit'\n        this.moveToTail(index)\n        if (updateAgeOnGet) {\n          this.updateItemAge(index)\n        }\n        this.statusTTL(status, index)\n        return v\n      }\n\n      // ok, it is stale or a forced refresh, and not already fetching.\n      // refresh the cache.\n      const p = this.backgroundFetch(k, index, options, fetchContext)\n      const hasStale = p.__staleWhileFetching !== undefined\n      const staleVal = hasStale && allowStale\n      if (status) {\n        status.fetch = hasStale && isStale ? 'stale' : 'refresh'\n        if (staleVal && isStale) status.returnedStale = true\n      }\n      return staleVal ? p.__staleWhileFetching : (p.__returned = p)\n    }\n  }\n\n  get(\n    k,\n    {\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      status,\n    } = {}\n  ) {\n    const index = this.keyMap.get(k)\n    if (index !== undefined) {\n      const value = this.valList[index]\n      const fetching = this.isBackgroundFetch(value)\n      this.statusTTL(status, index)\n      if (this.isStale(index)) {\n        if (status) status.get = 'stale'\n        // delete only if not an in-flight background fetch\n        if (!fetching) {\n          if (!noDeleteOnStaleGet) {\n            this.delete(k)\n          }\n          if (status) status.returnedStale = allowStale\n          return allowStale ? value : undefined\n        } else {\n          if (status) {\n            status.returnedStale =\n              allowStale && value.__staleWhileFetching !== undefined\n          }\n          return allowStale ? value.__staleWhileFetching : undefined\n        }\n      } else {\n        if (status) status.get = 'hit'\n        // if we're currently fetching it, we don't actually have it yet\n        // it's not stale, which means this isn't a staleWhileRefetching.\n        // If it's not stale, and fetching, AND has a __staleWhileFetching\n        // value, then that means the user fetched with {forceRefresh:true},\n        // so it's safe to return that value.\n        if (fetching) {\n          return value.__staleWhileFetching\n        }\n        this.moveToTail(index)\n        if (updateAgeOnGet) {\n          this.updateItemAge(index)\n        }\n        return value\n      }\n    } else if (status) {\n      status.get = 'miss'\n    }\n  }\n\n  connect(p, n) {\n    this.prev[n] = p\n    this.next[p] = n\n  }\n\n  moveToTail(index) {\n    // if tail already, nothing to do\n    // if head, move head to next[index]\n    // else\n    //   move next[prev[index]] to next[index] (head has no prev)\n    //   move prev[next[index]] to prev[index]\n    // prev[index] = tail\n    // next[tail] = index\n    // tail = index\n    if (index !== this.tail) {\n      if (index === this.head) {\n        this.head = this.next[index]\n      } else {\n        this.connect(this.prev[index], this.next[index])\n      }\n      this.connect(this.tail, index)\n      this.tail = index\n    }\n  }\n\n  get del() {\n    deprecatedMethod('del', 'delete')\n    return this.delete\n  }\n\n  delete(k) {\n    let deleted = false\n    if (this.size !== 0) {\n      const index = this.keyMap.get(k)\n      if (index !== undefined) {\n        deleted = true\n        if (this.size === 1) {\n          this.clear()\n        } else {\n          this.removeItemSize(index)\n          const v = this.valList[index]\n          if (this.isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('deleted'))\n          } else {\n            this.dispose(v, k, 'delete')\n            if (this.disposeAfter) {\n              this.disposed.push([v, k, 'delete'])\n            }\n          }\n          this.keyMap.delete(k)\n          this.keyList[index] = null\n          this.valList[index] = null\n          if (index === this.tail) {\n            this.tail = this.prev[index]\n          } else if (index === this.head) {\n            this.head = this.next[index]\n          } else {\n            this.next[this.prev[index]] = this.next[index]\n            this.prev[this.next[index]] = this.prev[index]\n          }\n          this.size--\n          this.free.push(index)\n        }\n      }\n    }\n    if (this.disposed) {\n      while (this.disposed.length) {\n        this.disposeAfter(...this.disposed.shift())\n      }\n    }\n    return deleted\n  }\n\n  clear() {\n    for (const index of this.rindexes({ allowStale: true })) {\n      const v = this.valList[index]\n      if (this.isBackgroundFetch(v)) {\n        v.__abortController.abort(new Error('deleted'))\n      } else {\n        const k = this.keyList[index]\n        this.dispose(v, k, 'delete')\n        if (this.disposeAfter) {\n          this.disposed.push([v, k, 'delete'])\n        }\n      }\n    }\n\n    this.keyMap.clear()\n    this.valList.fill(null)\n    this.keyList.fill(null)\n    if (this.ttls) {\n      this.ttls.fill(0)\n      this.starts.fill(0)\n    }\n    if (this.sizes) {\n      this.sizes.fill(0)\n    }\n    this.head = 0\n    this.tail = 0\n    this.initialFill = 1\n    this.free.length = 0\n    this.calculatedSize = 0\n    this.size = 0\n    if (this.disposed) {\n      while (this.disposed.length) {\n        this.disposeAfter(...this.disposed.shift())\n      }\n    }\n  }\n\n  get reset() {\n    deprecatedMethod('reset', 'clear')\n    return this.clear\n  }\n\n  get length() {\n    deprecatedProperty('length', 'size')\n    return this.size\n  }\n\n  static get AbortController() {\n    return AC\n  }\n  static get AbortSignal() {\n    return AS\n  }\n}\n\nexport default LRUCache\n"],"names":[],"sourceRoot":""}